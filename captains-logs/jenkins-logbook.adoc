= the Captain's log for Jenkins explorations

== Objectives of the journey:

* understand what is under the hood of Jenkins and how to install idempotent working configurations with Ansible.
* Experiment with the new functionality of Jenkins V2 as I can't try/use them at work.
* Explore and improve my understanding of using Docker in a complete Continuous Integration/Delivery pipeline.

== First steps (Aug 2016)

=== Sub-domain and reverse proxy

Create a separate sub-domain (ci.the-captains-shack.com) and serve it with the nginx used as a reverse proxy

* Create the sub-domaine via the OVH DNS management console.
   The type is `CNAME`. Do not forget the '.' after the domain name.
   I should investigate the syntax and the various options offered.
* create the `ci_proxy.conf` to be placed in the `/data/nginx/conf/sites-enabled` directory.
   I have two server entries: one that listens to port 80 (that redirects automatically to 443) and the main one for the SSL (443) port.
   The main forwarding is based on https://wiki.jenkins-ci.org/display/JENKINS/Jenkins+behind+an+NGinX+reverse+proxy[this jenkins documentation].
* Change the `request_certificates.sh`script to add a section for requesting the LetsEncrypt certificate for the subdomain. Running the whole file will either renew the existing certificate or request a new one if it doesn't exist yet.
* Adapt the docker-compose file to include the start of the standard jenkins docker image (alpine). I used the sample docker-compose of this https://github.com/dduportal/voxxed-lu-2016[voxxed-lu demo].
* Validate: use http and https to connect to the Jenkins server.

{nbsp}

=== Implement access control (using GitHub OAuth)

* this method, using the https://wiki.jenkins-ci.org/display/JENKINS/GitHub+OAuth+Plugin[GitHub Authentication Plugin], allows to use GitHub authentication to authorize access to Jenkins.
* The plugin installed interactively works. It requires several operation that will need to be automated: install the plugin, configure the (secret) ID keys generated on Github, configure the jenkins global settings).
  This must be automated so that it can be (re-)installed with Ansible.
* Installing the plugin requires to create a custom docker image that we can configure.
* The plugin (and dependencies) can be installed by executing the `install-plugins.sh` script available in the base image.
* At first it didn't work. The plugin (and dependencies) didn't show in the User Interface. I searched a long time for the problem. A very long time.
   I found the problem (grumbl, grumbl): by cutting and pasting the volume definition from the sample app, I also copied the plugin cache system.
   The plugins were installed correctly and then "overlayed" by the volume definition.
* Once the plugin installation mechanism is ok, it appears that, while the installer can search for the dependencies, it only downloads the version referenced in the plugin and not the latest as does the UI.
   This is not the expected behavior and indeed I get exceptions with the recommended versions.
   So I need to install the plugin via the UI and request the list of installed plugins. I then use this list as the list of plugins to install. Lousy.
* The configuration of the plugin can be done via a groovy script (`enableGitHubOAuth`). The script requires to set secret GitHub keys. They should be stored in the source repo.
   So I use the same technique as for the backup solution. The groovy script retrieves the needed values from environment variable set inside the container.
   These values are set via an environment file loaded by the docker-compose. The problem of storing this env file in the SCM is solved by using the Ansible Vault system (encrypted file).
* The initial configuration works and has been ported on the Jenkins Ansible role (and tested).
* While validating that the new Jenkins server can correctly access the Gogs (git) server some inconsistencies were found
   It looks that something is wrong with the Firewalld and the Docker configured IPtables.
   Without changing something structurally but restarting components, it now works.
   It has to be investigated further and ironed out.
* I opened an issue ( https://github.com/jenkinsci/docker/issues/327[# 327] ) on the github of the Jenkins Docker image about the behavior of the `install_plugins.sh`.

{nbsp}

=== Install a Java Artifact repository server

I want the Nexus server to be only reachable from the Jenkins and not from the Internet.
This will require setting up internal networks from the docker-compose (front/back)

I am not convinced about this: I will miss the user interface to verify and manage the server.
I then need to research how to activate the GitHub OAuth system.
The alternative, as I only need, in a first stage, to store dependencies of my projects, is to use Artifactory based on the voxxed-lu example.

I will first try with Nexus because this is what I know best and that it has a build in Docker repository (in the OSS version I hope).

* Create a DNS entry for the new subdomain `nexus.the-captains-shack.com` on the OVH console.
* Create the Ansible role and setup the new proxy configuration and update the LetsEncrypt request/update script
* Adapt the docker-compose file to add the nexus server
* First test failed with a "bad gateway" error.
  Connecting directly to the server via the exposed port, started the server correctly.
  Obviously it needed to initialize something that the reverse proxy couldn't do.
  After that initial connection, the nexus server could be connected via the main address.
* Configured a data volume to persist data.
* Changed the default admin password via the User Interface.
* I was only able to find how to add the RUT Real but need to research how to setup the Github OAuth.
* After some search, I come to the conclusion that this integration is less easy then on Jenkins.
  As this is not the main direction of my exploration, I will leave that particular subject for now.

{nbsp}

=== Make the first java compile with jenkins

After some very simple tests, I want now to tackle some real integration.
I need to industrialize the interaction with GOGS though.

* created a Jenkins user in GOGS and gave it a read access to my java project
* added (via the UI) the pipeline plugin
* started experimenting with building the project
* I am able to do a checkout of the sources but the Master doesn't have Maven installed. Obvious.
  Let's add a slave specialized in java build.
* Tried the method described in the voxxed-lu demo.
  It creates a container with the necessary tools for that agent.
  It then downloads the required jars from the master and tries to connect.
  This is where it fails with an authentication issue (anonymous is not allowed to perform the operation).
  As I enabled OAuth, I should use the authentication method described in the plugin notes.
  It uses a github personal access token to authenticate.
  This doesn't work. +
  These are some of the tests that I did : `java -jar ./jenkins-cli.jar -s http://jenkins:8080 --username="jmMeessen" help` (trying to login to display the help).
  After some research, it appears that this part is broken.
* I will try an alternative method (less automatic) to setup an agent: the SSL method.
  I plan to use the pre-packaged ssh-slave docker image.
  I will have to solve the scripting of the key generation problem and the configuration of the plugin.

=== Creating a jenkins slave with SSH

* To generate the jenkins server certificate, I will use a dedicated key-generator container to provision a volume with the ssh key.
  It is a better practice than to generate the key inside the container. +
  This is done by the `ssh-keygen` alpine based container.
  It uses the `jenkins-keys` volume that is then connected by the Jenkins container.
  The `ssh-keygen` container uses a bash file to perform the operation.
  It will generate the keys only if they are not already present.
* I spent quite some time to make the basic principle work.
  In the beginning the jenkins container was not able to connect to the ssh-slave container hence the jenkins application start the agent. +
  To debug the connection, I logged to the jenkins container (`docker-compose exec jenkins bash`) and tried to establish a connection
  with the slave container with `ssh -v -i /ssh-keys/id_rsa jenkins@ssh-agent`. +
  After some search, I found the issues. The first one was the ownership and access of the generated keypair.
  The key-gen container runs with user root. The generated files are thus by default owned by root and can't be read by the user running the
  jenkins application (jenkins). It took me a while to find the issue as the output of the ssh command was quite verbose.
  The second issue was that I didn't pass the public key correctly to the "run" command of the ssh-slave container.
  When using the environment variable method, it is important to specify it without quotes despite that it contains space.
  The way to check that the key is correctly loaded in the ssh-slave is to check the `~/.ssh/authorized_keys` file. +
  Once I got the ssh connection working at bash level, I observed that the User Interface in Jenkins to load the SSH key from an
  other location than the default one doesn't give any error if the file was not found (made a mistake in the name) or the access
  rights aren't correct (see above). It didn't find a way to view if it was correctly loaded and/or its value.
  Loading the ssh key with will not be an easy task.
* Once I have the different pieces working, I come to the conclusion that the strategy chosen will be hardly automatble.
  The issue is to retrieve the public key from the data volume so that it can be passed as an environment or command in the
  docker-compose. I will change the strategy and have probably the "slave SSH key" generated with Ansible before the compose file is
  executed. It is a real pity that initial method (slave connecting to master) fails because of the OAuth bug.


=== SSH Jenkins slave : "same player shoots again"

* The difficulty I had was to retrieve the public key so that I could use it in the compose file.
  To solve this the key pair must be available before the compose file is executed.
  This can be achieved with some Ansible. I inlcuded it in the main playbook of the jenkins role.
* The trick is to generate the key at setup. It will be re-generated at every system regeneration.
  The key is generated in a directory of host. It is mapped as a volume of the Jenkins container with the compose.
  It is important to set the ownership/access rights to the keys so that the user in the Jenkins container can reach it.
* After generating the keys, a script (create-key-env.sh) is executed to create the environment file correctly formatted (slave-keys.env) so that it can be loaded in the
  docker-compose.
* I am back to the state where I was at the end of the first tentative.
  Now I need to be able to load automatically the key in jenkins with some Groovy witchery.

=== SSH Jenkins slave : Loading the key with groovy

* I found an https://gist.github.com/hayderimran7/d6ab8a6a770cb970349e[article on the Internet] that shows an sample groovy script to load the key from the user's ~/.ssh directory.
  It doesn't show though how to proceed to load a key from a directory.
  But at least I have the name of the classes and methods involved in the SSH key loading.
* I search the source repositories and found the involved sources.
  The comments and the variable names are a precious help.
  I was able to adapt the groovy script (see `roles/jenkins/files/jenkins/load-slavery-key.groovy`) and run it interactively.
  The loaded key is as it should and the agent is correctly started by the master once correctly configured.
* Last issue to solve: adapt the script so that if the key is already loaded it is not reloaded (creates a duplicate).
* By looking at the groovy samples provided by Cloudbees, I found a snippet that lists the loaded credentials.
  I used this to loop through them and compare it with the comment.
  If is only if I didn't find a credential with that comment that I load it.
* It works interactively. But as it is late, I will try the automation tomorrow or later.

